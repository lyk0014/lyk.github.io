---
title: LLaVA o1：思维链推理在视觉模型的尝试
author: LYK
date: 2024-11-18 19:53:00 +0800
categories: [AIGC, MLLM]
tags: [LLaVA, o1, CoT, 101]
pin: true
media_subpath: '/posts/20241118'
---

## Intro
LLaVA-o1，介一个新颖的视觉语言模型, 能够进行多阶段的结构化和自主推理。  
推理过程：总结、标题、推理、结论。  
主要贡献：
1. 创建了带有详细推理注释的LLaVA-o1-100k数据集，支持<b>系统化</b>、<b>结构化</b>响应的训练。
2. 提出了一种阶段性beam搜索方法（推理时）  

结论：（11B）超越了更大甚至闭源模型的性能（Gemini-1.5、GPT-4o-mini、LLaMA-3.2-90B-Vision-instruct）


## Question List
- [ ] Q1: 什么是视觉语言模型（Vision-Language Models, VLMs）?
- [ ] Q2：常见的VLMs有哪些？
- [ ] Q3：针对VLMs，常见的评测方法有哪些？
- [ ] Q4：LLaVA-o1有哪些亮点？解决了什么问题？
- [ ] Q5：LLaVA-o1的主要方法是什么？
- [ ] Q6：LLaVA-o1-100k数据集的构建目标、标准、方法是什么？怎么评价数据量是否足够？
- [ ] Q7：下一步需要解决的问题？或努力的方向？

## Answer
Q1：什么是视觉语言模型（Vision-Language Models, VLMs）?
  
